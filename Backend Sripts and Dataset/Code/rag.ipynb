{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfaIYKtiJI0C",
        "outputId": "3de55287-4824-4ec0-f7fe-3f132785c2c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.23.2-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting weaviate-client\n",
            "  Downloading weaviate_client-4.5.6-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
            "  Downloading langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.42 (from langchain)\n",
            "  Downloading langchain_core-0.1.45-py3-none-any.whl (291 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.3/291.3 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.49-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Collecting validators==0.28.0 (from weaviate-client)\n",
            "  Downloading validators-0.28.0-py3-none-any.whl (39 kB)\n",
            "Collecting authlib<2.0.0,>=1.2.1 (from weaviate-client)\n",
            "  Downloading Authlib-1.3.0-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0.0,>=1.57.0 in /usr/local/lib/python3.10/dist-packages (from weaviate-client) (1.62.2)\n",
            "Collecting grpcio-tools<2.0.0,>=1.57.0 (from weaviate-client)\n",
            "  Downloading grpcio_tools-1.62.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio-health-checking<2.0.0,>=1.57.0 (from weaviate-client)\n",
            "  Downloading grpcio_health_checking-1.62.2-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (3.7)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from authlib<2.0.0,>=1.2.1->weaviate-client) (42.0.5)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting protobuf>=4.21.6 (from grpcio-health-checking<2.0.0,>=1.57.0->weaviate-client)\n",
            "  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools<2.0.0,>=1.57.0->weaviate-client) (67.7.2)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (2.22)\n",
            "Installing collected packages: validators, protobuf, packaging, orjson, mypy-extensions, jsonpointer, h11, typing-inspect, marshmallow, jsonpatch, httpcore, grpcio-tools, grpcio-health-checking, langsmith, httpx, dataclasses-json, authlib, weaviate-client, openai, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed authlib-1.3.0 dataclasses-json-0.6.4 grpcio-health-checking-1.62.2 grpcio-tools-1.62.2 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.16 langchain-community-0.0.34 langchain-core-0.1.45 langchain-text-splitters-0.0.1 langsmith-0.1.49 marshmallow-3.21.1 mypy-extensions-1.0.0 openai-1.23.2 orjson-3.10.1 packaging-23.2 protobuf-4.25.3 typing-inspect-0.9.0 validators-0.28.0 weaviate-client-4.5.6\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai weaviate-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uh0rj-UDJ0bz"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY=\"sk-proj-tHjnF4pK8tPw6jVVHa6MT3BlbkFJMh8L3z1jTVafjm7rg1MO\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcPWjlAqJ-Fh",
        "outputId": "b4a9bec8-9d82-4dc2-df38-d38dc337ebec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0wziGsFJ6S7",
        "outputId": "afe14747-bbf6-4cb7-dadc-b6294e09c8c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import dotenv\n",
        "dotenv.load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Cn1AW_C_NaZh"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zcdb5n7NNck2"
      },
      "outputs": [],
      "source": [
        "loader = TextLoader('cleaned_data.txt')\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUXM-tt1NwaA",
        "outputId": "20bd2e2b-7f1e-48f7-e857-e7968e6d8506"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 17087, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 13598, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 5321, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 30953, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2981, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 15882, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 12282, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 14708, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 16649, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1810, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 15204, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 8312, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2607, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 5452, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 10312, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1771, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 32251, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 28895, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 5204, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2367, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1703, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 11904, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 5968, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 14183, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 5230, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 7733, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 51932, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 34359, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1914, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 4259, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 9929, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 35711, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 4436, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 7817, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 15531, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 5811, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2150, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 5996, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 4763, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 15134, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2542, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 7822, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 13025, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 15427, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 3902, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2392, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 3647, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 10571, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 11330, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 4162, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 5118, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 9453, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 10302, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 11803, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 4663, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 3168, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 5448, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 27940, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 22592, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 3002, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 3460, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1640, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2190, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 879, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 10450, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 19437, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 9837, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 7121, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 44195, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 967, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 27067, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 6166, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1848, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2711, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1990, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 5304, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 9306, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2893, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 4552, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 8738, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2479, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1452, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 11065, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 8126, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 3390, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 6274, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1236, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 7268, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 9693, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 9958, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2501, which is longer than the specified 500\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03IuxXPwOLJL",
        "outputId": "05e7b36b-89ac-4b5f-e277-f47d1b4a849b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwO0PN6mN13G",
        "outputId": "0c20bff3-5607-4ca8-ec4f-60b026f088e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embedded weaviate is already listening on port 8079\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Weaviate\n",
        "import weaviate\n",
        "from weaviate.embedded import EmbeddedOptions\n",
        "\n",
        "client = weaviate.Client(\n",
        "  embedded_options = EmbeddedOptions()\n",
        ")\n",
        "\n",
        "vectorstore = Weaviate.from_documents(\n",
        "    client = client,\n",
        "    documents = chunks,\n",
        "    embedding = OpenAIEmbeddings(openai_api_key=\"sk-proj-tHjnF4pK8tPw6jVVHa6MT3BlbkFJMh8L3z1jTVafjm7rg1MO\"),\n",
        "    by_text = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FT-eePxdOhX1"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qeFCfvwOio7",
        "outputId": "86a43099-f1d3-4206-8121-8fdecaebd900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_variables=['context', 'question'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for a travel recommendation system. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\\n\"))]\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"You are an assistant for a travel recommendation system.\n",
        "Use the following pieces of retrieved context to answer the question.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "Use three sentences maximum and keep the answer concise.\n",
        "Question: {question}\n",
        "Context: {context}\n",
        "Answer:\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "RqdBrFQ7Ox_j",
        "outputId": "014798ab-da46-47db-a77f-7ed6dccd0485"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Visit the Anokhi Museum of Hand Printing in Amber, Rajasthan, India. The museum showcases a wide range of collections ranging from textiles, tools to equipment, etc. It is dedicated to the art of hand-block printing and provides a tactile experience of learning about the technique of block-printing craft.'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, openai_api_key=\"sk-proj-tHjnF4pK8tPw6jVVHa6MT3BlbkFJMh8L3z1jTVafjm7rg1MO\")\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever,  \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "query = \"i want to get fabrics where should i go?\"\n",
        "rag_chain.invoke(query)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
