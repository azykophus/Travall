{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Place</th>\n",
       "      <th>Relevant Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>Chandni Chowk</td>\n",
       "      <td>chandni chowk delhi place market food old shop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>Connaught Place</td>\n",
       "      <td>place connaught delhi shopping shops restauran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>Delhi Airport Metro Express</td>\n",
       "      <td>airport metro delhi station express new time w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>Friday Mosque (Jama Masjid)</td>\n",
       "      <td>mosque masjid delhi place visit shoes old red ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>Gurudwara Bangla Sahib</td>\n",
       "      <td>gurudwara place sikh sahib bangla delhi visit ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    City                        Place  \\\n",
       "0  Delhi                Chandni Chowk   \n",
       "1  Delhi              Connaught Place   \n",
       "2  Delhi  Delhi Airport Metro Express   \n",
       "3  Delhi  Friday Mosque (Jama Masjid)   \n",
       "4  Delhi       Gurudwara Bangla Sahib   \n",
       "\n",
       "                                     Relevant Review  \n",
       "0  chandni chowk delhi place market food old shop...  \n",
       "1  place connaught delhi shopping shops restauran...  \n",
       "2  airport metro delhi station express new time w...  \n",
       "3  mosque masjid delhi place visit shoes old red ...  \n",
       "4  gurudwara place sikh sahib bangla delhi visit ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset to examine its structure and contents\n",
    "data_path = \"C:/Users/amilb/Desktop/Sem 6/IR/Project/Travall/Final Project/Dataset/Combined_datasets/City_Place_RelReview.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amilb\\AppData\\Local\\Temp\\ipykernel_37500\\4272059951.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  delhi_data['Delhi Synthetic Review'] = delhi_data['Relevant Review'].apply(generate_longer_review)\n",
      "C:\\Users\\amilb\\AppData\\Local\\Temp\\ipykernel_37500\\4272059951.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  delhi_data['Label'] = delhi_data['Place']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Synthetic Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>area tourist enjoy site building years old hin...</td>\n",
       "      <td>Qutub Minar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green visit enjoyed crowded quite years really...</td>\n",
       "      <td>Humayun's Tomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jahan gate chowk audio new area places guide l...</td>\n",
       "      <td>Red Fort (Lal Quila)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>near items cheap old stalls streets really cro...</td>\n",
       "      <td>Chandni Chowk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>night water streets want cafe nice area really...</td>\n",
       "      <td>Hauz Khas Village</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Synthetic Review                 Label\n",
       "0  area tourist enjoy site building years old hin...           Qutub Minar\n",
       "1  green visit enjoyed crowded quite years really...        Humayun's Tomb\n",
       "2  jahan gate chowk audio new area places guide l...  Red Fort (Lal Quila)\n",
       "3  near items cheap old stalls streets really cro...         Chandni Chowk\n",
       "4  night water streets want cafe nice area really...     Hauz Khas Village"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "# Function to generate a longer synthetic review\n",
    "def generate_longer_review(keywords):\n",
    "    words = keywords.split()\n",
    "    random.shuffle(words)\n",
    "    # Ensuring each review is longer by using almost all keywords\n",
    "    return ' '.join(words[:max(20, len(words))])\n",
    "\n",
    "# Filter for places with the city label 'Delhi'\n",
    "delhi_data = data[data['City'] == 'Delhi']\n",
    "\n",
    "# Generate 500 synthetic reviews specifically for Delhi, using longer reviews\n",
    "delhi_data['Delhi Synthetic Review'] = delhi_data['Relevant Review'].apply(generate_longer_review)\n",
    "delhi_data['Label'] = delhi_data['Place']\n",
    "\n",
    "# Check if there are enough entries for Delhi or if we need to repeat some\n",
    "delhi_synthetic_data = pd.DataFrame(np.repeat(delhi_data[['Delhi Synthetic Review', 'Label']].values, 1000, axis=0), columns=['Synthetic Review', 'Label'])\n",
    "delhi_synthetic_data = delhi_synthetic_data.sample(n=500, random_state=42).reset_index(drop=True)\n",
    "delhi_synthetic_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this as evaluation data\n",
    "delhi_synthetic_data.to_csv(\"C:/Users/amilb/Desktop/Sem 6/IR/Project/Travall/Final Project/Dataset/Combined_datasets/Delhi_Evaluation Dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset: (500, 2)\n"
     ]
    }
   ],
   "source": [
    "# print the size of the dataset\n",
    "print(\"Size of the dataset:\", delhi_synthetic_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing a tf-idf vectorization on initial dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform \n",
    "delhi_data = pd.read_csv('C:/Users/amilb/Desktop/Sem 6/IR/Project/Travall/Final Project/Dataset/Dataset2/review_dataset/New Delhi_top_15_places_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Place</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Raw_Review</th>\n",
       "      <th>Wheelchair Accessibility</th>\n",
       "      <th>Visual Impairments</th>\n",
       "      <th>Mobility Impairments</th>\n",
       "      <th>Hearing Impairments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Chandni Chowk</td>\n",
       "      <td>dusty crowded chaotic great walk ride rickshaw...</td>\n",
       "      <td>3</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dusty, crowded and chaotic, it's great to have...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Chandni Chowk</td>\n",
       "      <td>times obviously place real india struggle dail...</td>\n",
       "      <td>2</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I have been there 4 times, obviously I just ca...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Chandni Chowk</td>\n",
       "      <td>came chandi chowk mend late fathers old automa...</td>\n",
       "      <td>5</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I came to Chandi Chowk to find somewhere to me...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Chandni Chowk</td>\n",
       "      <td>day delhi missed got tuc tuc red fort headed m...</td>\n",
       "      <td>2</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We only had 1 day in Delhi but this was not to...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Chandni Chowk</td>\n",
       "      <td>wish experience old delhi charm mad rush peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BE there if you wish to experience the old Del...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City          Place  \\\n",
       "0  New Delhi  Chandni Chowk   \n",
       "1  New Delhi  Chandni Chowk   \n",
       "2  New Delhi  Chandni Chowk   \n",
       "3  New Delhi  Chandni Chowk   \n",
       "4  New Delhi  Chandni Chowk   \n",
       "\n",
       "                                              Review  Rating       Name  Date  \\\n",
       "0  dusty crowded chaotic great walk ride rickshaw...       3  Anonymous   NaN   \n",
       "1  times obviously place real india struggle dail...       2  Anonymous   NaN   \n",
       "2  came chandi chowk mend late fathers old automa...       5  Anonymous   NaN   \n",
       "3  day delhi missed got tuc tuc red fort headed m...       2  Anonymous   NaN   \n",
       "4  wish experience old delhi charm mad rush peopl...       4  Anonymous   NaN   \n",
       "\n",
       "                                          Raw_Review  \\\n",
       "0  Dusty, crowded and chaotic, it's great to have...   \n",
       "1  I have been there 4 times, obviously I just ca...   \n",
       "2  I came to Chandi Chowk to find somewhere to me...   \n",
       "3  We only had 1 day in Delhi but this was not to...   \n",
       "4  BE there if you wish to experience the old Del...   \n",
       "\n",
       "   Wheelchair Accessibility  Visual Impairments  Mobility Impairments  \\\n",
       "0                       0.0                 0.0                   0.0   \n",
       "1                       0.0                 0.0                   0.0   \n",
       "2                       0.0                 0.0                   0.0   \n",
       "3                       0.0                 0.0                   0.0   \n",
       "4                       0.0                 0.0                   0.0   \n",
       "\n",
       "   Hearing Impairments  \n",
       "0                  1.0  \n",
       "1                  1.0  \n",
       "2                  1.0  \n",
       "3                  1.0  \n",
       "4                  1.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delhi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chandni Chowk</td>\n",
       "      <td>dusty crowded chaotic great walk ride rickshaw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Connaught Place</td>\n",
       "      <td>area good lot eateries available weekends plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhi Airport Metro Express</td>\n",
       "      <td>convenient journey airport city center option ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Friday Mosque (Jama Masjid)</td>\n",
       "      <td>review little unfair visited ramadan want insi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gurudwara Bangla Sahib</td>\n",
       "      <td>delhi way miss visiting place serene magnifice...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Place  \\\n",
       "0                Chandni Chowk   \n",
       "1              Connaught Place   \n",
       "2  Delhi Airport Metro Express   \n",
       "3  Friday Mosque (Jama Masjid)   \n",
       "4       Gurudwara Bangla Sahib   \n",
       "\n",
       "                                              Review  \n",
       "0  dusty crowded chaotic great walk ride rickshaw...  \n",
       "1  area good lot eateries available weekends plac...  \n",
       "2  convenient journey airport city center option ...  \n",
       "3  review little unfair visited ramadan want insi...  \n",
       "4  delhi way miss visiting place serene magnifice...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate reviews by concatenating them for each place\n",
    "aggregated_reviews = delhi_data.groupby('Place')['Review'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "aggregated_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 100)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100)\n",
    "\n",
    "# Fit and transform the aggregated reviews to create embeddings\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(aggregated_reviews['Review'])\n",
    "\n",
    "# Convert to array for similarity computation later\n",
    "tfidf_matrix_array = tfidf_matrix.toarray()\n",
    "\n",
    "tfidf_matrix_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport</th>\n",
       "      <th>amazing</th>\n",
       "      <th>architecture</th>\n",
       "      <th>area</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>best</th>\n",
       "      <th>big</th>\n",
       "      <th>building</th>\n",
       "      <th>buildings</th>\n",
       "      <th>built</th>\n",
       "      <th>...</th>\n",
       "      <th>visited</th>\n",
       "      <th>visiting</th>\n",
       "      <th>walk</th>\n",
       "      <th>want</th>\n",
       "      <th>water</th>\n",
       "      <th>way</th>\n",
       "      <th>went</th>\n",
       "      <th>wonderful</th>\n",
       "      <th>world</th>\n",
       "      <th>worth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.047495</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>0.111563</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.092516</td>\n",
       "      <td>0.017563</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.007916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043537</td>\n",
       "      <td>0.028447</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.065058</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>0.041805</td>\n",
       "      <td>0.031168</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>0.027210</td>\n",
       "      <td>0.041063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005907</td>\n",
       "      <td>0.027046</td>\n",
       "      <td>0.033001</td>\n",
       "      <td>0.104463</td>\n",
       "      <td>0.027046</td>\n",
       "      <td>0.084613</td>\n",
       "      <td>0.042927</td>\n",
       "      <td>0.011166</td>\n",
       "      <td>0.036980</td>\n",
       "      <td>0.015384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026054</td>\n",
       "      <td>0.022332</td>\n",
       "      <td>0.050123</td>\n",
       "      <td>0.042430</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.012655</td>\n",
       "      <td>0.021091</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>0.014392</td>\n",
       "      <td>0.024565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.612619</td>\n",
       "      <td>0.013119</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.122053</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.011245</td>\n",
       "      <td>0.025301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133297</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>0.031626</td>\n",
       "      <td>0.007965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063036</td>\n",
       "      <td>0.145665</td>\n",
       "      <td>0.114999</td>\n",
       "      <td>0.169516</td>\n",
       "      <td>0.041740</td>\n",
       "      <td>0.060481</td>\n",
       "      <td>0.078369</td>\n",
       "      <td>0.009975</td>\n",
       "      <td>0.152480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136295</td>\n",
       "      <td>0.072406</td>\n",
       "      <td>0.061333</td>\n",
       "      <td>0.056222</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>0.043444</td>\n",
       "      <td>0.065592</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.038333</td>\n",
       "      <td>0.128628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004114</td>\n",
       "      <td>0.057201</td>\n",
       "      <td>0.021051</td>\n",
       "      <td>0.025987</td>\n",
       "      <td>0.139955</td>\n",
       "      <td>0.062718</td>\n",
       "      <td>0.025407</td>\n",
       "      <td>0.021487</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078833</td>\n",
       "      <td>0.057201</td>\n",
       "      <td>0.022939</td>\n",
       "      <td>0.021777</td>\n",
       "      <td>0.034310</td>\n",
       "      <td>0.013792</td>\n",
       "      <td>0.032956</td>\n",
       "      <td>0.022503</td>\n",
       "      <td>0.018002</td>\n",
       "      <td>0.030924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    airport   amazing  architecture      area  beautiful      best       big  \\\n",
       "0  0.000280  0.047495      0.003216  0.111563   0.014100  0.092516  0.017563   \n",
       "1  0.005907  0.027046      0.033001  0.104463   0.027046  0.084613  0.042927   \n",
       "2  0.612619  0.013119      0.000234  0.006325   0.004451  0.122053  0.005622   \n",
       "3  0.000000  0.063036      0.145665  0.114999   0.169516  0.041740  0.060481   \n",
       "4  0.004114  0.057201      0.021051  0.025987   0.139955  0.062718  0.025407   \n",
       "\n",
       "   building  buildings     built  ...   visited  visiting      walk      want  \\\n",
       "0  0.002226   0.011587  0.007916  ...  0.043537  0.028447  0.061100  0.065058   \n",
       "1  0.011166   0.036980  0.015384  ...  0.026054  0.022332  0.050123  0.042430   \n",
       "2  0.000703   0.000000  0.001171  ...  0.003045  0.001406  0.011245  0.025301   \n",
       "3  0.078369   0.009975  0.152480  ...  0.136295  0.072406  0.061333  0.056222   \n",
       "4  0.021487   0.002627  0.010308  ...  0.078833  0.057201  0.022939  0.021777   \n",
       "\n",
       "      water       way      went  wonderful     world     worth  \n",
       "0  0.003687  0.041805  0.031168   0.014595  0.027210  0.041063  \n",
       "1  0.000792  0.012655  0.021091   0.007196  0.014392  0.024565  \n",
       "2  0.000000  0.133297  0.004451   0.008668  0.031626  0.007965  \n",
       "3  0.007255  0.043444  0.065592   0.019592  0.038333  0.128628  \n",
       "4  0.034310  0.013792  0.032956   0.022503  0.018002  0.030924  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print tfidf values with their names\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix_array, columns=tfidf_vectorizer.get_feature_names_out())\n",
    "#printfirst few 5 rows of the dataframe\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Sample user input\n",
    "user_input = [\"mosque historical architecture beautiful peaceful serene religious spiritual\"]\n",
    "\n",
    "# Convert the user input into TF-IDF embedding\n",
    "user_input_tfidf = tfidf_vectorizer.transform(user_input).toarray()\n",
    "\n",
    "# Compute the cosine similarity between user input and places\n",
    "user_similarity_scores = cosine_similarity(user_input_tfidf, tfidf_matrix_array)\n",
    "\n",
    "# Get the top 5 recommended places based on similarity scores\n",
    "top_indices = user_similarity_scores.argsort()[0][-10:][::-1]\n",
    "recommended_places_based_on_input_tfidf = aggregated_reviews.iloc[top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is: 66.8 %\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "              Chandni Chowk       0.43      1.00      0.60        29\n",
      "            Connaught Place       0.00      0.00      0.00        38\n",
      "Delhi Airport Metro Express       1.00      1.00      1.00        40\n",
      "Friday Mosque (Jama Masjid)       0.28      1.00      0.44        37\n",
      "     Gurudwara Bangla Sahib       0.00      0.00      0.00        35\n",
      "          Hauz Khas Village       1.00      1.00      1.00        32\n",
      "             Humayun's Tomb       1.00      1.00      1.00        31\n",
      "        ISKCON Temple Delhi       0.00      0.00      0.00        32\n",
      "                 India Gate       1.00      1.00      1.00        30\n",
      "               Lodhi Garden       1.00      1.00      1.00        31\n",
      "               Lotus Temple       0.00      0.00      0.00        24\n",
      "                Qutub Minar       1.00      1.00      1.00        37\n",
      "         Rashtrapati Bhavan       1.00      1.00      1.00        31\n",
      "       Red Fort (Lal Quila)       0.00      0.00      0.00        37\n",
      "    Swaminarayan Akshardham       0.53      1.00      0.69        36\n",
      "\n",
      "                   accuracy                           0.67       500\n",
      "                  macro avg       0.55      0.67      0.58       500\n",
      "               weighted avg       0.55      0.67      0.58       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amilb\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amilb\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amilb\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# getting the most recommended place for all rows in delhi synthetic data and calculating the accuracy\n",
    "accuracy = 0\n",
    "for index, row in delhi_synthetic_data.iterrows():\n",
    "    user_input = [row['Synthetic Review']]\n",
    "    user_input_tfidf = tfidf_vectorizer.transform(user_input).toarray()\n",
    "    user_similarity_scores = cosine_similarity(user_input_tfidf, tfidf_matrix_array)\n",
    "    top_indices = user_similarity_scores.argsort()[0][-1:][::-1]\n",
    "    recommended_place = aggregated_reviews.iloc[top_indices]['Place'].values[0]\n",
    "    if recommended_place == row['Label']:\n",
    "        accuracy += 1\n",
    "\n",
    "accuracy = accuracy / delhi_synthetic_data.shape[0] * 100\n",
    "print(\"Accuracy of the model is:\", accuracy, \"%\")\n",
    "\n",
    "# finding f1 score, and all the other evaluation metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get the top recommended place for each synthetic review\n",
    "predicted_labels = []\n",
    "for index, row in delhi_synthetic_data.iterrows():\n",
    "    user_input = [row['Synthetic Review']]\n",
    "    user_input_tfidf = tfidf_vectorizer.transform(user_input).toarray()\n",
    "    user_similarity_scores = cosine_similarity(user_input_tfidf, tfidf_matrix_array)\n",
    "    top_indices = user_similarity_scores.argsort()[0][-1:][::-1]\n",
    "    recommended_place = aggregated_reviews.iloc[top_indices]['Place'].values[0]\n",
    "    predicted_labels.append(recommended_place)\n",
    "\n",
    "# Get the actual labels\n",
    "actual_labels = delhi_synthetic_data['Label'].values\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(actual_labels, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using bert embeddings for the same\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the BERT model\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "# Encode the aggregated reviews\n",
    "aggregated_reviews['Review Embedding'] = aggregated_reviews['Review'].apply(lambda x: model.encode(x))\n",
    "\n",
    "# Convert the embeddings to a list\n",
    "aggregated_embeddings = np.array(aggregated_reviews['Review Embedding'].to_list())\n",
    "\n",
    "# Sample user input\n",
    "user_input = [\"mosque historical architecture beautiful peaceful serene religious spiritual\"]\n",
    "\n",
    "# Encode the user input\n",
    "user_input_embedding = model.encode(user_input)\n",
    "\n",
    "# Compute the cosine similarity between user input and places\n",
    "user_similarity_scores = cosine_similarity(user_input_embedding, aggregated_embeddings)\n",
    "\n",
    "# Get the top 5 recommended places based on similarity scores\n",
    "top_indices = user_similarity_scores.argsort()[0][-10:][::-1]\n",
    "recommended_places_based_on_input_bert = aggregated_reviews.iloc[top_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is: 77.0 %\n"
     ]
    }
   ],
   "source": [
    "# getting the most recommended place for all rows in delhi synthetic data and calculating the accuracy\n",
    "accuracy = 0\n",
    "\n",
    "for index, row in delhi_synthetic_data.iterrows():\n",
    "    user_input = [row['Synthetic Review']]\n",
    "    user_input_embedding = model.encode(user_input)\n",
    "    user_similarity_scores = cosine_similarity(user_input_embedding, aggregated_embeddings)\n",
    "    top_indices = user_similarity_scores.argsort()[0][-1:][::-1]\n",
    "    recommended_place = aggregated_reviews.iloc[top_indices]['Place'].values[0]\n",
    "    if recommended_place == row['Label']:\n",
    "        accuracy += 1\n",
    "\n",
    "accuracy = accuracy / delhi_synthetic_data.shape[0] * 100\n",
    "print(\"Accuracy of the model is:\", accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             precision    recall  f1-score   support\n",
      "\n",
      "              Chandni Chowk       0.00      0.00      0.00        29\n",
      "            Connaught Place       0.57      1.00      0.72        38\n",
      "Delhi Airport Metro Express       1.00      1.00      1.00        40\n",
      "Friday Mosque (Jama Masjid)       1.00      1.00      1.00        37\n",
      "     Gurudwara Bangla Sahib       1.00      1.00      1.00        35\n",
      "          Hauz Khas Village       1.00      1.00      1.00        32\n",
      "             Humayun's Tomb       0.00      0.00      0.00        31\n",
      "        ISKCON Temple Delhi       1.00      1.00      1.00        32\n",
      "                 India Gate       1.00      1.00      1.00        30\n",
      "               Lodhi Garden       1.00      1.00      1.00        31\n",
      "               Lotus Temple       0.00      0.00      0.00        24\n",
      "                Qutub Minar       0.30      1.00      0.46        37\n",
      "         Rashtrapati Bhavan       0.00      0.00      0.00        31\n",
      "       Red Fort (Lal Quila)       1.00      1.00      1.00        37\n",
      "    Swaminarayan Akshardham       1.00      1.00      1.00        36\n",
      "\n",
      "                   accuracy                           0.77       500\n",
      "                  macro avg       0.66      0.73      0.68       500\n",
      "               weighted avg       0.69      0.77      0.71       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amilb\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amilb\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amilb\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# finding f1 score, and all the other evaluation metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get the top recommended place for each synthetic review\n",
    "predicted_labels = []\n",
    "for index, row in delhi_synthetic_data.iterrows():\n",
    "    user_input = [row['Synthetic Review']]\n",
    "    user_input_embedding = model.encode(user_input)\n",
    "    user_similarity_scores = cosine_similarity(user_input_embedding, aggregated_embeddings)\n",
    "    top_indices = user_similarity_scores.argsort()[0][-1:][::-1]\n",
    "    recommended_place = aggregated_reviews.iloc[top_indices]['Place'].values[0]\n",
    "    predicted_labels.append(recommended_place)\n",
    "\n",
    "# Get the actual labels\n",
    "actual_labels = delhi_synthetic_data['Label'].values\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(actual_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the top n words from a document based on TF-IDF\n",
    "def extract_top_n_words(row, tfidf_vectorizer, n=60):\n",
    "    # Transform the document to TF-IDF vector\n",
    "    tfidf_vector = tfidf_vectorizer.transform([row])\n",
    "    # Get the feature names and tf-idf scores\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    sorted_items = sorted(zip(tfidf_vector.toarray().flatten(), feature_names), reverse=True)\n",
    "    # Get top n words\n",
    "    top_words = [word for _, word in sorted_items[:n]]\n",
    "    return ' '.join(top_words)\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=500)  # Considering the top 500 features\n",
    "vectorizer.fit(delhi_data['Review'])\n",
    "\n",
    "# Extract top words for each review\n",
    "aggregated_reviews['Relevant Review'] = aggregated_reviews['Review'].apply(lambda row: extract_top_n_words(row, vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place</th>\n",
       "      <th>Review</th>\n",
       "      <th>Review Embedding</th>\n",
       "      <th>Relevant Review</th>\n",
       "      <th>Relevant Review Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chandni Chowk</td>\n",
       "      <td>dusty crowded chaotic great walk ride rickshaw...</td>\n",
       "      <td>[-0.100976735, 0.9908482, 0.47805464, 0.065212...</td>\n",
       "      <td>chowk chandni market old food delhi place shop...</td>\n",
       "      <td>[-0.2339497, 0.65138096, 0.4171601, 0.1708652,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Connaught Place</td>\n",
       "      <td>area good lot eateries available weekends plac...</td>\n",
       "      <td>[-0.5678539, 0.48516074, 0.449588, 0.20512407,...</td>\n",
       "      <td>place shopping connaught shops cp restaurants ...</td>\n",
       "      <td>[-0.37223732, 0.28024632, 0.8378291, -0.043822...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhi Airport Metro Express</td>\n",
       "      <td>convenient journey airport city center option ...</td>\n",
       "      <td>[-1.1054823, 0.19444956, 0.35414392, 0.5531221...</td>\n",
       "      <td>airport metro delhi station express new travel...</td>\n",
       "      <td>[-1.0280166, -0.13376634, 0.40821144, 0.613782...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Friday Mosque (Jama Masjid)</td>\n",
       "      <td>review little unfair visited ramadan want insi...</td>\n",
       "      <td>[-0.032201856, 1.0281426, 0.60659826, 0.100594...</td>\n",
       "      <td>mosque masjid jama shoes old delhi camera larg...</td>\n",
       "      <td>[-0.2403737, 1.2502785, -0.0054552555, -0.0422...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gurudwara Bangla Sahib</td>\n",
       "      <td>delhi way miss visiting place serene magnifice...</td>\n",
       "      <td>[-0.43542767, 1.2588313, 0.09452545, 0.4163538...</td>\n",
       "      <td>gurudwara place sikh sahib visit bangla peace ...</td>\n",
       "      <td>[-0.0874833, 0.93175316, 0.7865939, -0.0335123...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Place  \\\n",
       "0                Chandni Chowk   \n",
       "1              Connaught Place   \n",
       "2  Delhi Airport Metro Express   \n",
       "3  Friday Mosque (Jama Masjid)   \n",
       "4       Gurudwara Bangla Sahib   \n",
       "\n",
       "                                              Review  \\\n",
       "0  dusty crowded chaotic great walk ride rickshaw...   \n",
       "1  area good lot eateries available weekends plac...   \n",
       "2  convenient journey airport city center option ...   \n",
       "3  review little unfair visited ramadan want insi...   \n",
       "4  delhi way miss visiting place serene magnifice...   \n",
       "\n",
       "                                    Review Embedding  \\\n",
       "0  [-0.100976735, 0.9908482, 0.47805464, 0.065212...   \n",
       "1  [-0.5678539, 0.48516074, 0.449588, 0.20512407,...   \n",
       "2  [-1.1054823, 0.19444956, 0.35414392, 0.5531221...   \n",
       "3  [-0.032201856, 1.0281426, 0.60659826, 0.100594...   \n",
       "4  [-0.43542767, 1.2588313, 0.09452545, 0.4163538...   \n",
       "\n",
       "                                     Relevant Review  \\\n",
       "0  chowk chandni market old food delhi place shop...   \n",
       "1  place shopping connaught shops cp restaurants ...   \n",
       "2  airport metro delhi station express new travel...   \n",
       "3  mosque masjid jama shoes old delhi camera larg...   \n",
       "4  gurudwara place sikh sahib visit bangla peace ...   \n",
       "\n",
       "                          Relevant Review Embeddings  \n",
       "0  [-0.2339497, 0.65138096, 0.4171601, 0.1708652,...  \n",
       "1  [-0.37223732, 0.28024632, 0.8378291, -0.043822...  \n",
       "2  [-1.0280166, -0.13376634, 0.40821144, 0.613782...  \n",
       "3  [-0.2403737, 1.2502785, -0.0054552555, -0.0422...  \n",
       "4  [-0.0874833, 0.93175316, 0.7865939, -0.0335123...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying sentence transformer on the relevant review and finding the accuracy\n",
    "# Encode the aggregated reviews\n",
    "# Load the BERT model\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "# Function to get the embeddings of a sentence\n",
    "def get_embeddings(sentence):\n",
    "    return model.encode(sentence)\n",
    "\n",
    "# Get the embeddings of the relevant reviews\n",
    "aggregated_reviews['Relevant Review Embeddings'] = aggregated_reviews['Relevant Review'].apply(lambda row: get_embeddings(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is: 92.60000000000001 %\n"
     ]
    }
   ],
   "source": [
    "# now we will calculate the accuracy\n",
    "# Convert the embeddings to a list\n",
    "aggregated_embeddings = np.array(aggregated_reviews['Relevant Review Embeddings'].to_list())\n",
    "\n",
    "# getting the most recommended place for all rows in delhi synthetic data and calculating the accuracy\n",
    "accuracy = 0\n",
    "for index, row in delhi_synthetic_data.iterrows():\n",
    "    user_input = [row['Synthetic Review']]\n",
    "    user_input_embedding = model.encode(user_input)\n",
    "    user_similarity_scores = cosine_similarity(user_input_embedding, aggregated_embeddings)\n",
    "    top_indices = user_similarity_scores.argsort()[0][-1:][::-1]\n",
    "    recommended_place = aggregated_reviews.iloc[top_indices]['Place'].values[0]\n",
    "    if recommended_place == row['Label']:\n",
    "        accuracy += 1\n",
    "\n",
    "accuracy = accuracy / delhi_synthetic_data.shape[0] * 100\n",
    "print(\"Accuracy of the model is:\", accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             precision    recall  f1-score   support\n",
      "\n",
      "              Chandni Chowk       1.00      1.00      1.00        29\n",
      "            Connaught Place       1.00      1.00      1.00        38\n",
      "Delhi Airport Metro Express       1.00      1.00      1.00        40\n",
      "Friday Mosque (Jama Masjid)       1.00      1.00      1.00        37\n",
      "     Gurudwara Bangla Sahib       1.00      1.00      1.00        35\n",
      "          Hauz Khas Village       1.00      1.00      1.00        32\n",
      "             Humayun's Tomb       0.46      1.00      0.63        31\n",
      "        ISKCON Temple Delhi       1.00      1.00      1.00        32\n",
      "                 India Gate       1.00      1.00      1.00        30\n",
      "               Lodhi Garden       1.00      1.00      1.00        31\n",
      "               Lotus Temple       1.00      1.00      1.00        24\n",
      "                Qutub Minar       0.00      0.00      0.00        37\n",
      "         Rashtrapati Bhavan       1.00      1.00      1.00        31\n",
      "       Red Fort (Lal Quila)       1.00      1.00      1.00        37\n",
      "    Swaminarayan Akshardham       1.00      1.00      1.00        36\n",
      "\n",
      "                   accuracy                           0.93       500\n",
      "                  macro avg       0.90      0.93      0.91       500\n",
      "               weighted avg       0.89      0.93      0.90       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amilb\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amilb\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amilb\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# print the classification report\n",
    "# Get the top recommended place for each synthetic review\n",
    "\n",
    "predicted_labels = []\n",
    "for index, row in delhi_synthetic_data.iterrows():\n",
    "    user_input = [row['Synthetic Review']]\n",
    "    user_input_embedding = model.encode(user_input)\n",
    "    user_similarity_scores = cosine_similarity(user_input_embedding, aggregated_embeddings)\n",
    "    top_indices = user_similarity_scores.argsort()[0][-1:][::-1]\n",
    "    recommended_place = aggregated_reviews.iloc[top_indices]['Place'].values[0]\n",
    "    predicted_labels.append(recommended_place)\n",
    "\n",
    "# Get the actual labels\n",
    "actual_labels = delhi_synthetic_data['Label'].values\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(actual_labels, predicted_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
